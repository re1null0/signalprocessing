{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f015fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import discrete_signal\n",
    "import matplotlib.pyplot as plt\n",
    "from idft import idft\n",
    "from dft import dft\n",
    "from scipy.io.wavfile import write\n",
    "import cmath\n",
    "import sounddevice as sd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e5ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class recordsound():\n",
    "   \n",
    "    def __init__(self, T, fs):\n",
    "    \n",
    "        self.T = T\n",
    "        self.fs = fs\n",
    "                \n",
    "    def solve(self):\n",
    "        \n",
    "        print('start recording')\n",
    "        voicerecording = sd.rec(int(self.T * self.fs), self.fs, 1)\n",
    "        sd.wait() \n",
    "        print('end recording')\n",
    "        write('myvoice.wav', self.fs, voicerecording) \n",
    "        \n",
    "        return voicerecording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab5e962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When prompted to speak, say 1. \n",
      "\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "When prompted to speak, say 2. \n",
      "\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n"
     ]
    }
   ],
   "source": [
    "T = 1  \n",
    "fs = 8000  \n",
    "num_recs = 10  \n",
    "digits = [1, 5] \n",
    "digit_recs = []\n",
    "\n",
    "for digit in digits:\n",
    "    partial_recs = np.zeros((num_recs, int(T*fs)))\n",
    "    print('When prompted to speak, say ' + str(digit) + '. \\n')\n",
    "    for i in range(num_recs):\n",
    "        time.sleep(2)\n",
    "        digit_recorder = recordsound(T, fs)\n",
    "        spoken_digit = digit_recorder.solve().reshape(int(T*fs))\n",
    "        partial_recs[i, :] = spoken_digit\n",
    "    digit_recs.append(partial_recs)\n",
    "\n",
    "\n",
    "np.save(\"recorded_digits.npy\", digit_recs)\n",
    "\n",
    "digit_recs = np.load(\"recorded_digits.npy\")\n",
    "digits = [1, 2]\n",
    "num_digits = len(digit_recs)\n",
    "num_recs, N = digit_recs[0].shape \n",
    "fs = 8000\n",
    "DFTs = []\n",
    "DFTs_c = []\n",
    "\n",
    "for digit_rec in digit_recs:\n",
    "    DFTs_aux = np.zeros((num_recs, N), dtype=np.complex_)\n",
    "    DFTs_c_aux = np.zeros((num_recs, N), dtype=np.complex_)\n",
    "    for i in range(num_recs):\n",
    "        rec_i = digit_rec[i, :]\n",
    "        energy_rec_i = np.linalg.norm(rec_i)\n",
    "        rec_i /= energy_rec_i\n",
    "        DFT_rec_i = dft(rec_i, fs)\n",
    "        [_, X, _, X_c] = DFT_rec_i.solve()\n",
    "        DFTs_aux[i, :] = X \n",
    "        DFTs_c_aux[i, :] = X_c\n",
    "    DFTs.append(DFTs_aux)\n",
    "    DFTs_c.append(DFTs_c_aux) \n",
    "\n",
    "np.save(\"spoken_digits_DFTs.npy\", DFTs)\n",
    "np.save(\"spoken_digits_DFTs_c.npy\", DFTs_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9ed065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When prompted to speak, say 1 or 2. \n",
      "\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n"
     ]
    }
   ],
   "source": [
    "T = 1  # recording time\n",
    "fs = 8000  # sampling frequency\n",
    "num_recs = 10  # number of recordings for the test set\n",
    "digit_recs = []\n",
    "\n",
    "partial_recs = np.zeros((num_recs, int(T*fs)))\n",
    "print('When prompted to speak, say 1 or 2' + '. \\n')\n",
    "for i in range(num_recs):\n",
    "    time.sleep(2)\n",
    "    digit_recorder = recordsound(T, fs)\n",
    "    spoken_digit = digit_recorder.solve().reshape(int(T*fs))\n",
    "    partial_recs[i, :] = spoken_digit\n",
    "digit_recs.append(partial_recs)\n",
    "\n",
    "# Storing recorded voices\n",
    "np.save(\"test_set.npy\", partial_recs)\n",
    "\n",
    "# Creating an audio file with the spoken digits\n",
    "test_set_audio = partial_recs.reshape(T*fs*num_recs)\n",
    "file_name = 'test_set_audio_rec.wav'\n",
    "write(file_name, fs, test_set_audio.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744afca8",
   "metadata": {},
   "source": [
    "Average comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dda4a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average spectrum comparison --- predicted labels: \n",
      "\n",
      "The accuracy is: 50.0\n"
     ]
    }
   ],
   "source": [
    "T = 1  # recording time\n",
    "fs = 8000  # sampling frequency\n",
    "\n",
    "test_set = np.load(\"test_set.npy\")\n",
    "\n",
    "# loads (DFTs of) training set\n",
    "training_set_DFTs = np.load(\"spoken_digits_DFTs.npy\")\n",
    "# Average spectra\n",
    "num_digits = len(training_set_DFTs)\n",
    "_, N = training_set_DFTs[0].shape\n",
    "average_spectra = np.zeros((num_digits, N), dtype=np.complex_)\n",
    "average_signal = np.zeros((num_digits, N), dtype=np.complex_)\n",
    "\n",
    "for i in range(num_digits):\n",
    "    # Average of modulus of spectra\n",
    "    average_spectra[i, :] = np.mean(np.absolute(training_set_DFTs[i]), axis=0)\n",
    "    iDFT = idft(average_spectra[i, :], fs, N)\n",
    "    y_demod, Treal = iDFT.solve_ifft()\n",
    "    average_signal[i, :] = y_demod\n",
    "\n",
    "num_recs, N = test_set.shape\n",
    "predicted_labels = np.zeros(num_recs)\n",
    "\n",
    "for i in range(num_recs):\n",
    "    rec_i = test_set[i, :]\n",
    "    # We can use the norm of the ith signal to normalize its DFT\n",
    "    energy_rec_i = np.linalg.norm(rec_i)\n",
    "    rec_i /= energy_rec_i\n",
    "\n",
    "    # Comparisons\n",
    "    inner_prods = np.zeros(num_digits)\n",
    "\n",
    "    for j in range(num_digits):\n",
    "        inner_prods[j] = np.linalg.norm(np.convolve(rec_i , average_signal[j, :],'same'))**2\n",
    "\n",
    "    predicted_labels[i] = np.argmax(inner_prods) + 1\n",
    "\n",
    "print(\"Average spectrum comparison --- predicted labels: \\n\")\n",
    "\n",
    "# Storing predicted labels\n",
    "np.save(\"predicted_labels_avg.npy\", predicted_labels)\n",
    "true_labels=np.array([1, 1, 1, 2, 2, 2, 1, 1, 1, 2])\n",
    "print('The accuracy is:',(1-sum(abs(true_labels-predicted_labels))/len(true_labels))*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d05f7a",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c472453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 1\n",
      "The number said is: 2\n",
      "The number said is: 2\n",
      "The number said is: 1\n",
      "The number said is: 2\n",
      "The number said is: 2\n",
      "The number said is: 2\n"
     ]
    }
   ],
   "source": [
    "T = 1  # recording time\n",
    "fs = 8000  # sampling frequency\n",
    "time_slots=20 # time of online recording\n",
    "\n",
    "# loads (DFTs of) training set\n",
    "training_set_DFTs = np.load(\"spoken_digits_DFTs.npy\")\n",
    "\n",
    "# Average spectra\n",
    "num_digits = len(training_set_DFTs)\n",
    "_, N = training_set_DFTs[0].shape\n",
    "average_spectra = np.zeros((num_digits, N), dtype=np.complex_)\n",
    "average_signal = np.zeros((num_digits, N), dtype=np.complex_)\n",
    "\n",
    "for i in range(num_digits):\n",
    "    # Average of modulus of spectra\n",
    "    average_spectra[i, :] = np.mean(np.absolute(training_set_DFTs[i]), axis=0)\n",
    "    iDFT = idft(average_spectra[i, :], fs, N)\n",
    "    y_demod, Treal = iDFT.solve_ifft()\n",
    "    average_signal[i, :] = y_demod\n",
    "\n",
    "\n",
    "for t in range(time_slots):\n",
    "    voicerecording = sd.rec(int(T * fs), fs, 1)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    rec_i = voicerecording.astype(np.float32)\n",
    "    rec_i=rec_i[:,0]\n",
    "\n",
    "    # We can use the norm of the ith signal to normalize its DFT\n",
    "    energy_rec_i = np.linalg.norm(rec_i)\n",
    "    rec_i /= energy_rec_i\n",
    "    # Comparisons\n",
    "    inner_prods = np.zeros(num_digits)\n",
    "\n",
    "    for j in range(num_digits):\n",
    "        inner_prods[j] = np.linalg.norm(np.convolve(rec_i , average_signal[j, :]))**2\n",
    "\n",
    "    print('The number said is:', np.argmax(inner_prods) + 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737ca0f",
   "metadata": {},
   "source": [
    "The lab we use the signal rather than just the spectrum to run it online. To do this, we use calculations in time representation of the signals where we record in parallel. In the code, we take 1s each and compute the norm of convolution with $h_y$ and $h_z$ continuously and repeat the same procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7befe122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
