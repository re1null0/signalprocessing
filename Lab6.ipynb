{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ffbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import discrete_signal\n",
    "import matplotlib.pyplot as plt\n",
    "from idft import idft\n",
    "from dft import dft\n",
    "from scipy.io.wavfile import write\n",
    "import cmath\n",
    "import sounddevice as sd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b086d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "class recordsound():\n",
    "   \n",
    "    def __init__(self, T, fs):\n",
    "    \n",
    "        self.T = T\n",
    "        self.fs = fs\n",
    "                \n",
    "    def solve(self):\n",
    "        \n",
    "        print('start recording')\n",
    "        voicerecording = sd.rec(int(self.T * self.fs), self.fs, 1)\n",
    "        sd.wait()  # Wait until recording is finished\n",
    "        print('end recording')\n",
    "        write('myvoice.wav', self.fs, voicerecording)  # Save as WAV file \n",
    "        \n",
    "        return voicerecording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480546b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When prompted to speak, say 1. \n",
      "\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "When prompted to speak, say 2. \n",
      "\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n",
      "start recording\n",
      "end recording\n"
     ]
    }
   ],
   "source": [
    "T = 1  \n",
    "fs = 8000  \n",
    "num_recs = 10  \n",
    "digits = [1, 2] \n",
    "digit_recs = []\n",
    "\n",
    "for digit in digits:\n",
    "    partial_recs = np.zeros((num_recs, int(T*fs)))\n",
    "    print('When prompted to speak, say ' + str(digit) + '. \\n')\n",
    "    for i in range(num_recs):\n",
    "        time.sleep(2)\n",
    "        digit_recorder = recordsound(T, fs)\n",
    "        spoken_digit = digit_recorder.solve().reshape(int(T*fs))\n",
    "        partial_recs[i, :] = spoken_digit\n",
    "    digit_recs.append(partial_recs)\n",
    "\n",
    "\n",
    "np.save(\"recorded_digits.npy\", digit_recs)\n",
    "\n",
    "digit_recs = np.load(\"recorded_digits.npy\")\n",
    "digits = [1, 2]\n",
    "num_digits = len(digit_recs)\n",
    "num_recs, N = digit_recs[0].shape \n",
    "fs = 8000\n",
    "DFTs = []\n",
    "DFTs_c = []\n",
    "\n",
    "for digit_rec in digit_recs:\n",
    "    DFTs_aux = np.zeros((num_recs, N), dtype=np.complex_)\n",
    "    DFTs_c_aux = np.zeros((num_recs, N), dtype=np.complex_)\n",
    "    for i in range(num_recs):\n",
    "        rec_i = digit_rec[i, :]\n",
    "        energy_rec_i = np.linalg.norm(rec_i)\n",
    "        rec_i /= energy_rec_i\n",
    "        DFT_rec_i = dft(rec_i, fs)\n",
    "        [_, X, _, X_c] = DFT_rec_i.solve()\n",
    "        DFTs_aux[i, :] = X \n",
    "        DFTs_c_aux[i, :] = X_c\n",
    "    DFTs.append(DFTs_aux)\n",
    "    DFTs_c.append(DFTs_c_aux) \n",
    "\n",
    "np.save(\"spoken_digits_DFTs.npy\", DFTs)\n",
    "np.save(\"spoken_digits_DFTs_c.npy\", DFTs_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1  # recording time\n",
    "fs = 8000  # sampling frequency\n",
    "num_recs = 10  # number of recordings for the test set\n",
    "digit_recs = []\n",
    "\n",
    "partial_recs = np.zeros((num_recs, int(T*fs)))\n",
    "print('When prompted to speak, say 1 or 2' + '. \\n')\n",
    "for i in range(num_recs):\n",
    "    time.sleep(2)\n",
    "    digit_recorder = recordsound(T, fs)\n",
    "    spoken_digit = digit_recorder.solve().reshape(int(T*fs))\n",
    "    partial_recs[i, :] = spoken_digit\n",
    "digit_recs.append(partial_recs)\n",
    "\n",
    "# Storing recorded voices\n",
    "np.save(\"test_set.npy\", partial_recs)\n",
    "\n",
    "# Creating an audio file with the spoken digits\n",
    "test_set_audio = partial_recs.reshape(T*fs*num_recs)\n",
    "file_name = 'test_set_audio_rec.wav'\n",
    "write(file_name, fs, test_set_audio.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b51a852e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average spectrum comparison --- predicted labels: \n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "T = 1 \n",
    "fs = 8000  \n",
    "test_set = np.load(\"test_set.npy\")\n",
    "training_set_DFTs = np.abs(np.load(\"spoken_digits_DFTs.npy\"))\n",
    "\n",
    "num_digits = len(training_set_DFTs)\n",
    "_, N = training_set_DFTs[0].shape\n",
    "average_spectra = np.zeros((num_digits, N), dtype=np.complex_)\n",
    "\n",
    "for i in range(num_digits):\n",
    "    average_spectra[i, :] = np.mean(training_set_DFTs[i], axis=0) \n",
    "\n",
    "num_recs, N = test_set.shape\n",
    "predicted_labels = np.zeros(num_recs)\n",
    "    \n",
    "for i in range(num_recs):\n",
    "    rec_i = test_set[i, :]\n",
    "    energy_rec_i = np.linalg.norm(rec_i)\n",
    "    rec_i /= energy_rec_i\n",
    "    DFT_rec_i = dft(rec_i, fs)\n",
    "    [_, X, _, X_c] = DFT_rec_i.solve()\n",
    "\n",
    "    inner_prods = np.zeros(num_digits) \n",
    "    for j in range(num_digits):\n",
    "        inner_prods[j] = np.inner(np.abs(X), np.abs(average_spectra[j, :]))\n",
    "    predicted_labels[i] = np.argmax(inner_prods) + 1\n",
    "    \n",
    "print(\"Average spectrum comparison --- predicted labels: \\n\")\n",
    "print(np.matrix(predicted_labels[:, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d7fbf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbor comparison --- predicted labels: \n",
      "\n",
      "[[1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "T = 1 \n",
    "fs = 8000  \n",
    "test_set = np.load(\"test_set.npy\")\n",
    "\n",
    "training_set_DFTs = np.load(\"spoken_digits_DFTs.npy\")\n",
    "num_digits = len(training_set_DFTs)\n",
    "\n",
    "num_recs, N = test_set.shape\n",
    "predicted_labels = np.zeros(num_recs)\n",
    "training_set_size, _ = training_set_DFTs[0].shape\n",
    "\n",
    "for i in range(num_recs):\n",
    "    rec_i = test_set[i, :]\n",
    "    energy_rec_i = np.linalg.norm(rec_i)\n",
    "    rec_i /= energy_rec_i\n",
    "    DFT_rec_i = dft(rec_i, fs)\n",
    "    [_, X, _, X_c] = DFT_rec_i.solve()\n",
    "\n",
    "    inner_prods = np.zeros((num_digits, training_set_size))\n",
    "    for j in range(num_digits):\n",
    "        for k in range(training_set_size):\n",
    "            sample_dft = (training_set_DFTs[j])[k, :]  \n",
    "            inner_prods[j, k] = np.inner(np.abs(X), np.abs(sample_dft))\n",
    "    max_position = np.unravel_index(np.argmax(inner_prods), inner_prods.shape)  \n",
    "    predicted_labels[i] = max_position[0] + 1  \n",
    "\n",
    "print(\"Nearest neighbor comparison --- predicted labels: \\n\")\n",
    "print(np.matrix(predicted_labels[:, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e331de",
   "metadata": {},
   "source": [
    "In our case, average spectrum comparison ad nearest neighbor comparison outputs overlap, meaning that they have 100% accuracy level. Of course, in real-world setting, it is not possible given a lot of noise in data and a immmense amount of data present to digital systems. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
